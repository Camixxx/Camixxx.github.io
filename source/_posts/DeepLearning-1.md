---
title: Deep Learning - 基础知识
categories:
- 深度学习
tags:
- Deep Learning
- Math
date: 2017-11-04 13:30:01
---

##  深度学习所需数学知识整理
其实只是因为自己忘完了，然后把自己忘掉的写成了笔记

1. 线性代数：标量、向量、矩阵和张量
张量（Tensor）坐标超过两维的数组

2. 矩阵和向量相乘
A(B+C)=AB+AC  分配律
A(BC)=(AB)C   结合律
transepose(AB)=transepose(B)transepose(A)

3. 单位矩阵和逆矩阵
矩阵求逆的时间代价很大，我上一篇blog中提到过

4. 线性相关和生成子空间
若矩阵A的逆存在，那么Ax=b对于每一个向量b恰好存在一个解，但是对于方程组而言，b中某些有可能无解，或者存在无限多个解。
所以一组向量的线性组合，是指每个向量乘以对应标量系数的和。
一组向量的生成子空间，是原始向量线性组合后能达到的点的集合。

5. 范数
用于衡量向量的大小。

6. 特殊类型的矩阵和向量
对角矩阵、对称矩阵 、正交矩阵（矩阵的转置 = 矩阵的逆 的一个方阵）

7. 特征分解
特征分解则是将一个矩阵分解成一组特征向量和特征值。方阵A的特征向量 v 指的是：Av = λv，λ就是特征值。

8. 奇异值分解

9. Moore-Penrose 伪逆
如果对A求逆的时候，A的行数大于列数，则可能 Ax=y --> x=By 无解，若A的行数小于列数，则可能有无数多个解
对A进行奇异值分解得到U,D,V
A的伪逆 = V*D的伪逆*U的转置

10. 迹运算
返回的是矩阵对角元素的和。

11. 行列式

12. 主成分分析

##  信息论基础

  参考《统计自然语言处理技术》

  20世纪40年代，Claude Shannon提出的理论，对于任何类型的信息源和信息通道，香浓希望在理论上能给出数据压缩率（熵H，或称为柯尔莫戈罗夫复杂度K）和数据传输率的最高值。
  香农证明了只要数据传输速率低于信道容量C，即可获得我们期望的任意错误率。

1. 熵（Entropy）

  表示单个随机变量的不确定性的均值，随机变量的熵越大，它的不确定性越大，越不容易正确的估计其值的概率。

    H(p) = H(x) = -Sigma(p(x)log2p(x))

## 数值计算

## 机器学习知识整理


<!--more-->
